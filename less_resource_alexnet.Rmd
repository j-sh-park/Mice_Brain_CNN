---
title: "alexnet"
output: html_document
date: "2023-03-27"
---
```{r setup, warning=FALSE}
library(tidyverse)
library(EBImage)
library(pracma)
library(randomForest)
library(ggimage)
```

# Lab - 2 cluster

```{r}
cluster_A_files = list.files("data/Biotechnology_small/data_processed/cell_images/cluster_8/",
                             full.names = TRUE)

cluster_B_files = list.files("data/Biotechnology_small/data_processed/cell_images/cluster_13/",
                             full.names = TRUE)

cluster_C_files = list.files("data/Biotechnology_small/data_processed/cell_images/cluster_22/",
                             full.names = TRUE)

cluster_D_files = list.files("data/Biotechnology_small/data_processed/cell_images/cluster_2/",
                             full.names = TRUE)

cell_boundaries_raw = read.csv("data/Biotechnology_small/data_processed/cell_boundaries.csv.gz")

cluster_A_cell_ids = gsub(".*cell_|.png", "", cluster_A_files)
cluster_B_cell_ids = gsub(".*cell_|.png", "", cluster_B_files)
cluster_C_cell_ids = gsub(".*cell_|.png", "", cluster_C_files)
cluster_D_cell_ids = gsub(".*cell_|.png", "", cluster_D_files)

cell_boundaries = cell_boundaries_raw |>
  filter(cell_id %in% c(cluster_A_cell_ids, cluster_B_cell_ids, cluster_C_cell_ids, cluster_D_cell_ids))

cluster_A_imgs = sapply(cluster_A_files, readImage, simplify = FALSE)
cluster_A_imgs_resized = lapply(cluster_A_imgs, resize, w = 50, h = 50)
cluster_A_imgs_tiled = tile(EBImage::combine(cluster_A_imgs_resized))
#display(cluster_A_imgs_tiled)

cluster_B_imgs = sapply(cluster_B_files, readImage, simplify = FALSE)
cluster_B_imgs_resized = lapply(cluster_B_imgs, resize, w = 50, h = 50)
cluster_B_imgs_tiled = tile(EBImage::combine(cluster_B_imgs_resized))
#display(cluster_B_imgs_tiled)

cluster_C_imgs = sapply(cluster_C_files, readImage, simplify = FALSE)
cluster_C_imgs_resized = lapply(cluster_C_imgs, resize, w = 50, h = 50)
cluster_C_imgs_tiled = tile(EBImage::combine(cluster_C_imgs_resized))

cluster_D_imgs = sapply(cluster_D_files, readImage, simplify = FALSE)
cluster_D_imgs_resized = lapply(cluster_D_imgs, resize, w = 50, h = 50)
cluster_D_imgs_tiled = tile(EBImage::combine(cluster_D_imgs_resized))

```


```{r}
i = 1

cell_boundary = cell_boundaries |>
  filter(cell_id %in% cluster_A_cell_ids[i])

#cell_boundary

img = cluster_A_imgs[[i]]

# rescale the boundary according to the pixels
# 1 indexing, hence need +1
pixels = dim(img)
cell_boundary$vertex_x_scaled <- 1+((cell_boundary$vertex_x - min(cell_boundary$vertex_x))/0.2125)
cell_boundary$vertex_y_scaled <- 1+((cell_boundary$vertex_y - min(cell_boundary$vertex_y))/0.2125)

# visualise the image with the cell boundary
#display(img, method = "raster")
#points(cell_boundary$vertex_x_scaled, cell_boundary$vertex_y_scaled, type = "b", lwd = 10, col = "yellow")
```

```{r}
# identify which pixels are inside or outside of the cell segment using inpolygon
pixel_locations = expand.grid(seq_len(nrow(img)), seq_len(ncol(img)))

pixels_inside = inpolygon(x = pixel_locations[,1],
                          y = pixel_locations[,2],
                          xp = cell_boundary$vertex_x_scaled,
                          yp = cell_boundary$vertex_y_scaled,
                          boundary = TRUE)

img_inside = img
img_inside@.Data <- matrix(pixels_inside, nrow = nrow(img), ncol = ncol(img))

#display(img_inside, method = "raster")
```

```{r}
get_inside = function(cellID, img, cell_boundaries) {
  
  cell_boundary = cell_boundaries |>
    filter(cell_id %in% cellID)
  
  # rescale the boundary according to the pixels
  pixels = dim(img)
  cell_boundary$vertex_x_scaled <- 1+((cell_boundary$vertex_x - min(cell_boundary$vertex_x))/0.2125)
  cell_boundary$vertex_y_scaled <- 1+((cell_boundary$vertex_y - min(cell_boundary$vertex_y))/0.2125)
  
  # identify which pixels are inside or outside of the cell segment using inpolygon
  pixel_locations = expand.grid(seq_len(nrow(img)), seq_len(ncol(img)))
  
  pixels_inside = inpolygon(x = pixel_locations[,1],
                            y = pixel_locations[,2],
                            xp = cell_boundary$vertex_x_scaled,
                            yp = cell_boundary$vertex_y_scaled,
                            boundary = TRUE)
  
  img_inside = img
  img_inside@.Data <- matrix(pixels_inside, nrow = nrow(img), ncol = ncol(img))
  
  return(img_inside)
}

mask_resize = function(img, img_inside, w = 50, h = 50) {
  
  img_mask = img*img_inside
  
  # then, transform the masked image to the same number of pixels, 50x50
  img_mask_resized = resize(img_mask, w, h)
  
  return(img_mask_resized)
}
```


```{r}
#display(mask_resize(cluster_A_imgs[[1]], get_inside(cluster_A_cell_ids[1], cluster_A_imgs[[1]], cell_boundaries)),vmethod = "raster")
```

```{r}
cluster_A_imgs_inside = mapply(get_inside, cluster_A_cell_ids, cluster_A_imgs, MoreArgs = list(cell_boundaries = cell_boundaries), SIMPLIFY = FALSE)
cluster_A_imgs_masked_resized = mapply(mask_resize, cluster_A_imgs, cluster_A_imgs_inside, SIMPLIFY = FALSE)

#display(cluster_A_imgs_inside[[1]], method = "raster")
```

```{r}
cluster_B_imgs_inside = mapply(get_inside, cluster_B_cell_ids, cluster_B_imgs, MoreArgs = list(cell_boundaries = cell_boundaries), SIMPLIFY = FALSE)
cluster_B_imgs_masked_resized = mapply(mask_resize, cluster_B_imgs, cluster_B_imgs_inside, SIMPLIFY = FALSE)

#display(cluster_B_imgs_inside[[1]], method = "raster")
```


```{r}
cluster_C_imgs_inside = mapply(get_inside, cluster_C_cell_ids, cluster_C_imgs, MoreArgs = list(cell_boundaries = cell_boundaries), SIMPLIFY = FALSE)
cluster_C_imgs_masked_resized = mapply(mask_resize, cluster_C_imgs, cluster_C_imgs_inside, SIMPLIFY = FALSE)

cluster_D_imgs_inside = mapply(get_inside, cluster_D_cell_ids, cluster_D_imgs, MoreArgs = list(cell_boundaries = cell_boundaries), SIMPLIFY = FALSE)
cluster_D_imgs_masked_resized = mapply(mask_resize, cluster_D_imgs, cluster_D_imgs_inside, SIMPLIFY = FALSE)
```


# Random Forest

```{r}
y = factor(rep(c("cluster_A", "cluster_B", "cluster_C", "cluster_D"), times = c(length(cluster_A_cell_ids), length(cluster_B_cell_ids), length(cluster_C_cell_ids), length(cluster_D_cell_ids))))
x = cbind(do.call(cbind, lapply(cluster_A_imgs_masked_resized,c)),
          do.call(cbind, lapply(cluster_B_imgs_masked_resized,c)),
          do.call(cbind, lapply(cluster_C_imgs_masked_resized,c)),
          do.call(cbind, lapply(cluster_D_imgs_masked_resized,c))
          )

rf = randomForest(x = t(x), y = y)
# rf
```

```{r}
# importance_img = Image(data = matrix(rf$importance, 50, 50))
# display(importance_img/quantile(importance_img, 0.99), method = "raster")
```

```{r}
cluster_A_img_features = mapply(computeFeatures,
                                x = cluster_A_imgs_inside,
                                ref = cluster_A_imgs,
                                MoreArgs = list(expandRef = NULL))
cluster_B_img_features = mapply(computeFeatures,
                                x = cluster_B_imgs_inside,
                                ref = cluster_B_imgs,
                                MoreArgs = list(expandRef = NULL))
cluster_C_img_features = mapply(computeFeatures,
                                x = cluster_C_imgs_inside,
                                ref = cluster_C_imgs,
                                MoreArgs = list(expandRef = NULL))
cluster_D_img_features = mapply(computeFeatures,
                                x = cluster_D_imgs_inside,
                                ref = cluster_D_imgs,
                                MoreArgs = list(expandRef = NULL))

xf = cbind(cluster_A_img_features, cluster_B_img_features, cluster_C_img_features, cluster_D_img_features)

rff = randomForest(x = t(xf), y = y)
# rff
```


```{r}
# pc = princomp(t(xf), cor = TRUE)
#
# features_pc_df = data.frame(PC1 = pc$scores[,1],
#                             PC2 = pc$scores[,2],
#                             cluster = y,
#                             image = c(cluster_A_files, cluster_B_files))
#
# ggplot(features_pc_df, aes(x = PC1, y = PC2)) +
#   geom_point(aes(colour = cluster)) +
#   geom_image(aes(image = image), size = 0.03)
```

# Deep Learning
```{r, warning=FALSE, message=FALSE}
library(reticulate)
library(RBioFormats)
library(keras)
library(tensorflow)
tensorflow::set_random_seed(2023)

imgs_masked_resized_64 = mapply(mask_resize, c(cluster_A_imgs, cluster_B_imgs, cluster_C_imgs, cluster_D_imgs),
                                 c(cluster_A_imgs_inside, cluster_B_imgs_inside, cluster_C_imgs_inside, cluster_D_imgs_inside),
                                 MoreArgs = list(w = 224, h = 224), SIMPLIFY = FALSE)

num_images = length(imgs_masked_resized_64)
img_names <- names(imgs_masked_resized_64)

x <- array(dim=c(num_images, 224, 224, 1))

for (i in 1:num_images) {
  x[i,,,1] <- imgs_masked_resized_64[[i]]@.Data
}

input_shape = dim(x)[2:4]

```

```{r}
input_shape
dim(x)
```


## alexnet
- The AlexNet network input expects a 227x227 RGB (3 channels) image --> (227, 227, 3)
- With categorical cross entropy, predicts everything to be 2 and error rate of 0.4883721.

```{r}
model_function <- function(learning_rate = 0.020) {
  
  k_clear_session()
  
  model <- keras_model_sequential() %>%
    
    # 1st layer
    layer_conv_2d(filters = 32, kernel_size = c(11,11), strides = c(4,4), activation = 'relu', input_shape = input_shape, padding="same") %>% 
    layer_batch_normalization() %>%
    layer_max_pooling_2d(pool_size = c(3, 3), strides = c(2,2)) %>% 
    
    # 2nd layer
    layer_conv_2d(filters = 64, kernel_size = c(5,5), strides=c(1,1), activation = 'relu', padding = "same") %>% 
    layer_batch_normalization() %>%
    layer_max_pooling_2d(pool_size = c(3, 3), strides = c(2,2)) %>% 
    
    # 3rd layer
    layer_conv_2d(filters = 128, kernel_size = c(3,3), strides=c(1,1), activation = 'relu', padding = "same") %>% 
    layer_batch_normalization() %>%
    
    # 4th layer
    layer_conv_2d(filters = 256, kernel_size = c(3,3), strides=c(1,1), activation = 'relu', padding = "same") %>%
    layer_batch_normalization() %>%
    
    # 5th layer
    layer_conv_2d(filters = 512, kernel_size = c(3,3), strides=c(1,1), activation = 'relu', padding = "same") %>% 
    layer_batch_normalization() %>%
    layer_max_pooling_2d(pool_size = c(3, 3), strides = c(2,2)) %>% 
    
    # 6th layer
    layer_flatten() %>% 
    layer_dense(units = 4096, activation = 'relu') %>% 
    layer_dropout(rate = 0.5) %>% 
    
    # 7th layer
    layer_dense(units = 4096, activation = 'relu') %>%
    layer_dropout(rate = 0.5) %>%
    
    # 8th layer
    layer_dense(units = 4, activation = 'softmax')
  
  model %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_sgd(learning_rate = learning_rate),
    metrics = "accuracy"
  )
  
  return(model)
  
}

# Let this model compile and inspect its architecture

model <- model_function()
model
```

## Train model
```{r}
batch_size <- 32
epochs <- 100

yy = model.matrix(~ y - 1)
```

```{r}
dim(yy)
dim(x)
```


```{r}
hist <- model %>% fit(
  x = x,
  y = yy,
  batch_size = batch_size,
  steps_per_epoch = num_images %/% batch_size,
  epochs = epochs, 
  validation_split = 0.2,
  verbose = 2
)

plot(hist)
```

```{r}
pred <- model %>% predict(x)
head(pred)
```
```{r}
dim(pred)
```


```{r}
pred_class = apply(pred, 1, which.max)
pred_class
```

```{r}
table(pred_class, y)
```

```{r}
# resubstituition error rate
1-(sum(diag(table(pred_class, y)))/length(y))

# accuracy
(sum(diag(table(pred_class, y)))/length(y))
```